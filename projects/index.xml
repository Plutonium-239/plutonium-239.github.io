<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>pu239's page</title><link>https://plutonium-239.github.io/projects/</link><description>Recent content on pu239's page</description><image><title>pu239's page</title><url>https://plutonium-239.github.io/bmth+av.png</url><link>https://plutonium-239.github.io/bmth+av.png</link></image><generator>Hugo -- 0.134.2</generator><language>en-us</language><lastBuildDate>Tue, 18 Jun 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://plutonium-239.github.io/projects/index.xml" rel="self" type="application/rss+xml"/><item><title>`memsave_torch`</title><link>https://plutonium-239.github.io/projects/memsave_torch/</link><pubDate>Tue, 18 Jun 2024 00:00:00 +0000</pubDate><guid>https://plutonium-239.github.io/projects/memsave_torch/</guid><description>Lowering PyTorch&amp;#39;s Memory Consumption for Selective Differentiation</description></item><item><title>Q-MAGC</title><link>https://plutonium-239.github.io/projects/qmagc/</link><pubDate>Fri, 05 Apr 2024 00:00:00 +0000</pubDate><guid>https://plutonium-239.github.io/projects/qmagc/</guid><description>Attributed Graph Clustering via Modularity Aided Coarsening</description></item><item><title>Segmentation using CLIP</title><link>https://plutonium-239.github.io/projects/clipseg/</link><pubDate>Mon, 17 Oct 2022 00:00:00 +0000</pubDate><guid>https://plutonium-239.github.io/projects/clipseg/</guid><description>&lt;h2 id="zero-shot-segmentation-using-large-pre-trained-language-image-models-like-clip">Zero-shot segmentation using large pre-trained language-image models like CLIP&lt;/h2>
&lt;p>In this project, we explored language-driven zero-shot semantic segmentation using large pre-trained language-vision classification models like CLIP.&lt;/p>
&lt;p>We made changes in the vision branch of CLIP, which includes architectures like ResNets and Vision Transformers (ViT) to be replaced with other segmentation based architectures like PSPNet, DeepLab, DPT.&lt;/p>
&lt;p>We have used PSPNet along with CLIP&amp;rsquo;s text transformer (frozen). This gives us a good starting point for results. However, with just this, the segmentation maps are blobby and the boundaries are not well-defined, though the classes are in their correct approximate locations. This is because the image encoder is tied to the text encoder&amp;rsquo;s embeddings (semantically) because of training. We can resolve this by adding PSPNet without removing the CLIP image encoder and using CLIP&amp;rsquo;s maps as pseudo-labels for training our segmentation model.
We are testing out methods to improve this.&lt;/p></description></item></channel></rss>